# Kubernetes 集群组件

![K8s 集群主从架构](https://s2.ax1x.com/2020/01/04/ld7zdg.png)

## Master Components

Kubernetes 主要由以下几个核心组件组成：

- etcd：是高可用的 key/value 存储系统，用于持久化存储集群中的所有资源对象，比如：Node，Pod，Serivce，RC,namespace 等。API server 提供了操作 etcd 的封装接口 API，以 Rest 的方式提供，这些 API 基本上都是集群中资源对象的增删改查及监听资源变化的接口，比如创建 Pod、RC，监听 Pod 的变化等接口。API server 是连接其他所有服务组件的中间枢纽。

- kube-apiserver：提供了资源对象的唯一操作入口，其他组件都必须通过它提供的 API 来操作资源数据，通过对相关的资源数据全量查询与变化监听，这些组件可以近乎实时地完成相关的业务功能。比如提交一个新的 Pod 到 kube-apiserve 中，kube-controller-manger 可以立即就发现并开始作用。它还有一套完备的安全机制，包括认证、授权及准入控制等相关模块。

- kube-controller-manger：集群内部的管理控制中心，主要完成了集群的故障检测和恢复的自动化工作。比如对 RC 定义的 Pod 进行维护；根据 Service 和 Pod 的关系，完成服务的 Endpoints 对象的创建和更新；还有 Node 的发现、管理和状态监控，死亡容器所占资源及本地缓存的镜像文件的清理等工作。

- kube-scheduler: 集群的调度器，负责 Pod 在集群节点中的调度分配，也负责 Volume（CVI）和网络（CNI）的管理，按照预定的调度策略将 Pod 调度到相应的机器上；

## Node Components

- kubelet：负责本地节点上 Pod 的创建、修改、监控、删除等生命周期管理，同时会上报本 Node 的状态信息到 API server。

- kube-proxy：实现 Service 的代理及软件模式的负载均衡器。

- kubectl：集群内部的客户端可以直接使用 kubectl 命令管理集群；集群外的客户端需要使用 kubectl Porxy 进行反向代理来访问 API server。

- cAdvisor: 在 Node 节点运行的 kubectl 服务中内嵌了一个 cAdvisor 服务，cAdvisor 是谷歌的开源项目，用于实时监控 Docker 上运行的容器的性能指标。

# 组件通信

Kubernetes 多组件之间的通信原理为 apiserver 负责 etcd 存储的所有操作，且只有 apiserver 才直接操作 etcd 集群。apiserver 对内（集群中的其他组件）和对外（用户）提供统一的 REST API，其他组件均通过 apiserver 进行通信。controller manager、scheduler、kube-proxy 和 kubelet 等均通过 apiserver watch API 监测资源变化情况，并对资源作相应的操作。所有需要更新资源状态的操作均通过 apiserver 的 REST API 进行。apiserver 也会直接调用 kubelet API（如 logs, exec, attach 等），默认不校验 kubelet 证书，但可以通过 `--kubelet-certificate-authority` 开启（而 GKE 通过 SSH 隧道保护 它们之间的通信）。

比如典型的创建 Pod 的流程为：

![Pod 创建流程](https://i.postimg.cc/TPpwpQsn/image.png)

用户通过 REST API 创建一个 Pod，apiserver 将其写入 etcd。scheduluer 检测到未绑定 Node 的 Pod，开始调度并更新 Pod 的 Node 绑定，kubelet 检测到有新的 Pod 调度过来，通过 container runtime 运行该 Pod，kubelet 通过 container runtime 取到 Pod 状态，并更新到 apiserver 中。

# 使用的端口号

![端口之间数据流动](https://i.postimg.cc/yxX6wGJC/image.png)

## Master node(s)

| Protocol | Direction | Port Range | Purpose                          |
| -------- | --------- | ---------- | -------------------------------- |
| TCP      | Inbound   | `6443*`    | Kubernetes API server            |
| TCP      | Inbound   | 8080       | Kubernetes API insecure server   |
| TCP      | Inbound   | 2379-2380  | etcd server client API           |
| TCP      | Inbound   | 10250      | Kubelet API                      |
| TCP      | Inbound   | 10251      | kube-scheduler healthz           |
| TCP      | Inbound   | 10252      | kube-controller-manager healthz  |
| TCP      | Inbound   | 10253      | cloud-controller-manager healthz |
| TCP      | Inbound   | 10255      | Read-only Kubelet API            |
| TCP      | Inbound   | 10256      | kube-proxy healthz               |

## Worker node(s)

| Protocol | Direction | Port Range  | Purpose               |
| -------- | --------- | ----------- | --------------------- |
| TCP      | Inbound   | 4194        | Kubelet cAdvisor      |
| TCP      | Inbound   | 10248       | Kubelet healthz       |
| TCP      | Inbound   | 10249       | kube-proxy metrics    |
| TCP      | Inbound   | 10250       | Kubelet API           |
| TCP      | Inbound   | 10255       | Read-only Kubelet API |
| TCP      | Inbound   | 10256       | kube-proxy healthz    |
| TCP      | Inbound   | 30000-32767 | NodePort `Services**` |
